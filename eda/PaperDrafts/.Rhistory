split_pioneers
# Chunk 5
# My code:
class(split_pioneers)
# Chunk 6
# My code:
statisticians<-lapply(split_pioneers,str_to_upper)
# Chunk 7
# My code:
rbind(statisticians)
# Chunk 8
# My code:
pioneers_df<-do.call(rbind,statisticians)
pioneers_df
class(pioneers_df)
# Chunk 9
# My code:
pioneers_df<-data.frame(pioneers_df)
colnames(pioneers_df)<-c("name","byear")
pioneers_df
class(pioneers_df)
# Chunk 10
# My code:
class(pioneers_df$name)
class(pioneers_df$byear)
pioneers_df$name<-as.character(pioneers_df$name)
class(pioneers_df$name)
pioneers_df$byear<-as.integer(pioneers_df$byear)
class(pioneers_df$byear)
# Chunk 11
data(sleep)
# Chunk 12
# My code:
tapply(sleep$extra,sleep$group,mean)
split(sleep, sleep$ID)
#My code:
split_sleep<-lapply(1:10,function(x) x^2 )
#My code:
split_sleep<-lapply(1:10,function(x) x^2 )
split_sleep
#My code:
split_sleep<-lapply(1:10,function(id_num)  data.frame(sleep$extra[sleep$ID==id_num],sleep$group[sleep$ID==id_num],id_num,row.names=c("extra","group","ID")))
split_sleep
#My code:
split_sleep<-lapply(1:10,function(id_num)  data.frame(sleep$extra[sleep$ID==id_num],sleep$group[sleep$ID==id_num],id_num,row.names=c("extra","group","ID")))
split_sleep
#My code:
split_sleep<-lapply(1:10,function(id_num)  data.frame(c(sleep$extra[sleep$ID==id_num],sleep$group[sleep$ID==id_num],id_num),row.names=c("extra","group","ID")))
split_sleep
#My code:
split_sleep<-lapply(1:10,function(id_num)  data.frame(c(sleep$extra[sleep$ID==id_num],sleep$group[sleep$ID==id_num],id_num)))
split_sleep
#My code:
split_sleep<-lapply(1:10,function(id_num) subset(sleep,sleep$ID==id_num))
split_sleep
split(sleep, sleep$ID)
class(split_sleep)
split_sleep["group 1"]
split_sleep[[1]]
split_sleep[1]
split_sleep$'1'
split_sleep$"1"
split_sleep$1
split_sleep[1]
ss1<-data.frame(split_sleep[1])
ss1
ss1[extra]
ss1$extra
ss1$extra[1]
ss1$extra[1]-ss1$extra[2]
# My code:
vapply(1:10,function(id_num){ ss_df<-data.frame(split_sleep[id_num])
return(ss_df$extra[2]-ss_df$extra[1])
} )
# My code:
vapply(1:10,function(id_num){ ss_df<-data.frame(split_sleep[id_num])
return(ss_df$extra[2]-ss_df$extra[1])
} , FUN.VALUE = list)
# My code:
vapply(1:10,function(id_num){ ss_df<-data.frame(split_sleep[id_num])
return(ss_df$extra[2]-ss_df$extra[1])
} , FUN.VALUE = list(10))
# My code:
vapply(1:10,function(id_num){ ss_df<-data.frame(split_sleep[id_num])
return(ss_df$extra[2]-ss_df$extra[1])
} , FUN.VALUE = double(10))
# My code:
vapply(1:10,function(id_num){ ss_df<-data.frame(split_sleep[id_num])
return(ss_df$extra[2]-ss_df$extra[1])
} , FUN.VALUE = double(1))
irs
iris
# My code:
data(iris)
View(iris)
View(iris)
# My code:
data(iris)
iris_len<-select(iris,ends_with("Length"))
# My code:
iris_len<-select(iris,ends_with("Length"))
# My code:
iris_len<-select(iris,ends_with("Length"))
iris_len
# My code:
no_petal<-select(iris,-ends_with("Length"))
no_petal
# My code:
no_petal<-select(iris,-starts_with("Petal"))
no_petal
# My code:
species<-select(iris,Species)
species
# My code:
species_name<-select(iris,Species)
species_name
# My code:
mutate(iris,length_sum=Petal.Length+Septal.Length)
iris
# My code:
mutate(iris,length_sum=Petal.Length+Sepal.Length)
iris
# My code:
add_length<-mutate(iris,length_sum=Petal.Length+Sepal.Length)
add_length
View(species)
rm(species)
irisa
iris
# My code:
only_setosa<-filter(iris,Species=="setosa")
# My code:
only_setosa<-filter(iris,Species=="setosa")
only_setosa
# My code:
nonsense_filter<-filter(iris,str_detect(Species,"[aeiou]{4}")&sum(Sepal.Length,Sepal.Width)<8)
# My code:
nonsense_filter<-filter(iris,str_detect(Species,"[aeiou]{4}")&sum(Sepal.Length,Sepal.Width)<8)
nonsense_filter
# My code:
nonsense_filter<-filter(iris,str_detect(Species,"[aeiou]{4}"))
nonsense_filter
# My code:
nonsense_filter<-filter(iris,Species %in% "[aeiou]{4}")
nonsense_filter
# My code:
nonsense_filter<-filter(grepl("[aeiou]{4}", Species))
# My code:
nonsense_filter<-filter(grepl("[aeiou]{4}", iris$Species))
# My code:
nonsense_filter<-filter(iris,grepl("[aeiou]{4}", iris$Species))
# My code:
nonsense_filter<-filter(iris,grepl("[aeiou]{4}", iris$Species))
nonsense_filter
# My code:
filter(iris,"[aeiou]"%in%Species)
# My code:
filter(iris,"[aeiou]"%in%iris$Species)
# My code:
str_detect(iris$Species,"[aeiou]{4}")
# My code:
str_detect(iris$Species,"[aeiou]")
# My code:
str_detect(iris$Species,"[!aeiou]")
# My code:
str_detect(iris$Species,"[!aeiou]")
# My code:
str_detect(iris$Species,"[aeiou]{2}")
# My code:
str_detect(iris$Species,"[aeiou][aeiou]")
# My code:
str_detect(iris$Species,"[aeiou]")
# My code:
str_detect(iris$Species,".[aeiou]")
# My code:
str_detect(iris$Species,"(a|e|i|o|u)")
# My code:
str_detect(iris$Species,"(a|e|i|o|u){4}")
# My code:
str_detect(iris$Species,"[a|e|i|o|u]{4}")
# My code:
str_detect(iris$Species,"$c")
# My code:
str_detect(iris$Species,"[aeiou]{1}[aeiou]{1}[aeiou]{1}[aeiou]{1}")
iris$Species
class(iris$Species)
# My code:
iris_char<-iris
as.character(iris_char$Species)
class(iris_char$Species)
#str_detect(iris$Species,"[aeiou]{1}[aeiou]{1}[aeiou]{1}[aeiou]{1}")
# My code:
str_detect(iris$Species,"[aeiou]{1}[aeiou]{1}[aeiou]{1}[aeiou]{1}")
# My code
avg_sw<-sapply(iris$Sepal.Width,mean)
avg_sw
rm(avg_sw)
rm
ls
ls
# My code
avg_sw<-sapply(iris$Sepal.Width,mean)
avg_sl<-sapply(iris$Sepal.Length,mean)
sepal_avg_by_species<-mutate(iris,c(avg_sw,avg_sl))
# My code
avg_sw<-sapply(iris$Sepal.Width,mean)
avg_sl<-sapply(iris$Sepal.Length,mean)
# My code:
factorized<-iris
if(factorized$Sepal.Width>3){
factorized$Sepal.Width="wide"
} else {
factorized$Sepal.Width="narrorw"
}
as.double(factorized$Sepal.Width)
factorized$Sepal.Width
iris$Sepal.Width
class(iris$Sepal.Width)
# My code:
factorized<-iris
for(i in 1:length(factorized$Sepal.Width)){
if(factorized$Sepal.Width>3){
factorized$Sepal.Width="wide"
} else {
factorized$Sepal.Width="narrorw"
}
}
# My code:
factorized<-iris$Sepal.Width
for(i in 1:length(factorized)){
if(factorized>3){
factorized="wide"
} else {
factorized="narrorw"
}
}
knitr::opts_chunk$set(echo = TRUE)
library(sp)
library(ggmap)
library(tidyr)
library(readr)
library(plyr)
library(dplyr)
library(ggvis)
library(tidyr)
library(stringr)
library(lubridate)
library(ggplot2)
library(readr)
library(data.table)
library(rworldmap)
library(maps)
library(mapdata)
library(maptools)
library(scales)
#library(RgoogleMaps)
#library(tmap)
library(sp)
library(rgdal)
library(rgeos)
library(RColorBrewer)
library(grid)
library(gridExtra)
library(pander)
library(formattable)
setwd("C:/Users/Rebecca/Dropbox/School/2016_su_School/stat133/finalproject_angry_ladies/eda/PaperDrafts")
# read in the data and define parameters:
# data file names:
file_stops <- "../../clean_data/StopData_clean.csv"
file_berkcensus2010 <- "../../clean_data/berk_census2010_clean.csv"
file_berkcensus2010map <-"../../clean_data/berk_census2010_mapdata.rds"
file_tables <-  "../../clean_data/Tables_AgeSexRacePopStop.rds"
file_calls <-  "../../clean_data/CallsForService.rds"
file_arrests <- "../../raw_data/Berkeley_PD_Log_-_Arrests.csv"
file_jail <- "../../raw_data/Berkeley_PD_Log_-_Jail_Bookings.csv"
# read in the data:
# Police Stop Data:
stops <- read_csv(file = file_stops)
# Census 2010 Data by Polygonal Tract Number:
berkcensus2010 <- read_csv(file = file_berkcensus2010)
# Census 2010 Data by Polygonal Tract Number, ready for mapping:
berkcensus2010map <- readRDS(file_berkcensus2010map)
# Police Calls for service:
callservice <- read_csv(file = file_calls)
# Tables to use in paper:
tables <- readRDS(file = file_tables)
ss <- as.data.frame(tables[5]) # stop data by race proportional to population
pop1 <- as.data.frame(tables[4]) # census data population count table.
race <- as.data.frame(tables[3]) # race population count
sex <- as.data.frame(tables[2]) # sex population count
age <- as.data.frame(tables[1]) # age population count
# arrest data:
arrest <- read_csv(file_arrests)
# jail data:
jail <- read.csv(file_jail)
## Location info:
latmax <- max(stops$lat, na.rm = TRUE)
latmin <- min(stops$lat, na.rm = TRUE)
lonmax <- max(stops$long, na.rm = TRUE)
lonmin <- min(stops$long, na.rm = TRUE)
latvals <- c(latmin, latmax)
lonvals <- c(lonmin, lonmax)
# get rid of the axes theme:
ditch_the_axes <- theme(
axis.text = element_blank(),
axis.line = element_blank(),
axis.ticks = element_blank(),
panel.border = element_blank(),
panel.grid = element_blank(),
axis.title = element_blank()
)
# get the plain Berkeley map from Google:
# zoomed out berkeley map:
berkMap = map = get_map(location = c( lon = mean(lonvals), lat = mean(latvals) ), zoom = 12)
berkgg_zoom1 <-ggmap(berkMap) +
xlim(-122.335, lonmax) + ylim(latvals) +
ditch_the_axes
# zoomed in berkeley map:
berkMap2 = map = get_map(location = c( lon = mean(lonvals), lat = mean(latvals) ), zoom = 14)
berkgg_zoom2 <-ggmap(berkMap2) +
ditch_the_axes
### CENSUS DATA MAPS:
# create color palette:
p <- colorRampPalette(c("white", "red"))(128)
palette(p)
# create the maps:
# stop data map
map_stop1 <- berkgg_zoom2 +
geom_point(data = stops, aes(x=long,y=lat), alpha = .1) +
ggtitle("Berkeley Police Stops, 2015-2016")
map_stop1
# populatrion density map
popdenmap <- berkgg_zoom1 +
geom_polygon(data = berkcensus2010map, aes(x = long, y = lat, group = group, fill = Percent.Berkeley), color = "white", alpha = .7) +
ggtitle("2010 Population Density") +
labs(fill = "Percent") +
scale_fill_gradientn(colors = p)
# black population:
black2 <- berkgg_zoom1 +
geom_polygon(data = berkcensus2010map, aes(x = long, y = lat, group = group, fill = Percent.Black), color = "white", alpha = .7) +
scale_fill_gradientn(colors = p, limits = c(0,1)) +
guides( fill = "none" ) +
ggtitle("% Black")
# white population:
w2 <- berkgg_zoom1 +
geom_polygon(data = berkcensus2010map, aes(x = long, y = lat, group = group, fill = Percent.White), color = "white", alpha = .7) +
scale_fill_gradientn(colors = p, limits = c(0,1)) +
guides( fill = "none" ) +
ggtitle("% White")
# asian population:
a2 <- berkgg_zoom1 +
geom_polygon(data = berkcensus2010map, aes(x = long, y = lat, group = group, fill = Percent.Asian), color = "white", alpha = .7) +
scale_fill_gradientn(colors = p, limits = c(0,1)) +
guides( fill = "none" ) +
ggtitle("% Asian")
# hispanic population:
h2 <- berkgg_zoom1 +
geom_polygon(data = berkcensus2010map, aes(x = long, y = lat, group = group, fill = Percent.Hispanic), color = "white", alpha = .7) +
scale_fill_gradientn(colors = p, limits = c(0,1)) +
guides( fill = "none" ) +
ggtitle( "% Hispanic")
# other population:
o2 <- berkgg_zoom1 +
geom_polygon(data = berkcensus2010map, aes(x = long, y = lat, group = group, fill = Percent.Other), color = "white", alpha = .7) +
scale_fill_gradientn(colors = p, limits = c(0,1)) +
guides( fill = "none" ) +
ggtitle("% Other")
# bar graphs based on stop data:
names(ss)[2:3] <- c("Percent Stopped", "Percent Population Stopped")
bargraph1 <- ggplot(ss, aes(Race, `Percent Stopped`, fill = Race))+
geom_bar(stat = "identity") +
guides( fill = FALSE)
bargraph2 <- ggplot(ss, aes(Race, `Percent Population Stopped`, fill = Race))+
geom_bar(stat = "identity") +
guides( fill = FALSE)
# STOP DENSITY MAP:
stopdensitymap <- berkgg_zoom2 +
stat_density2d(aes(x = long, y = lat, fill= ..level.., alpha = .2* ..level..),
size = 2, bins = 5, data = stops, geom = "polygon") +
scale_fill_gradient(low = "black", high = "red") +
theme (panel.grid.major = element_blank (), # remove major grid
panel.grid.minor = element_blank ()  # remove minor grid
)+
ggtitle("All BPD Stops Density, 2015-2016") +
labs(alpha = element_blank())+
guides(alpha = FALSE)
# stop density
stopdensitymap4 <- berkgg_zoom2 +
stat_density2d( aes(x = long, y = lat, fill = ..level.., alpha = ..level..),
bins = I(5), geom = "polygon", data = stops ) +
scale_fill_gradient2( "StopDensity",
low = "white", mid = "orange", high = "red", midpoint = 100) +
labs(x = "Longitude", y = "Latitude") +
scale_alpha(range = c(.2, .55), guide = FALSE) +
ggtitle("Berkeley Police Stop Density Map, 2015-2016") +
guides(fill = "none")
stopdensitymap4
# stop density by race
stopdensitymap3 <- berkgg_zoom2 +
stat_density2d( aes(x = long, y = lat, fill = ..level.., alpha = ..level..),
bins = I(5), geom = "polygon", data = stops ) +
scale_fill_gradient2( "StopDensity",
low = "white", mid = "orange", high = "red", midpoint = 100) +
labs(x = "Longitude", y = "Latitude") + facet_grid( ~ Race ) +
scale_alpha(range = c(.2, .55), guide = FALSE) +
ggtitle("Berkeley Police Stop Density Map by Race") +
guides(fill = guide_colorbar(barwidth = 1.5, barheight = 10)) +
guides(fill = FALSE)
stopdensitymap3
# stops leading to arrests by race:
df <- subset(stops, as.character(Enforcement) == "Arrest")
map_arrested1 <- berkgg_zoom1 +
geom_point(aes(x = long, y = lat, colour = Race), data = df, alpha = 0.5) +
theme (
panel.grid.major = element_blank (), # remove major grid
panel.grid.minor = element_blank (),  # remove minor grid
axis.text = element_blank (),
axis.title = element_blank (),
axis.ticks = element_blank ()
) +
ggtitle("Police Stops Leading to Arrests") +
facet_grid(~ Race) +
guides( colour = FALSE)
# stops by reason:
map_reasons1 <- berkgg_zoom2 +
geom_point(aes(x = long, y = lat, colour = Reason), data = stops, alpha = .7) +
theme (
panel.grid.major = element_blank (), # remove major grid
panel.grid.minor = element_blank (),  # remove minor grid
axis.text = element_blank (),
axis.title = element_blank (),
axis.ticks = element_blank ()
) +
ggtitle("Police Stops by Reason")
# arrest data histogram by race
histogram_arrest1 <- ggplot(na.omit(arrest))+
geom_bar(aes(x=Age,
fill = Race))+
facet_wrap(~Race)+
labs(x= "Age",
y = "Number of people",
title = "Arrest Data")
# jail data histogram by race
histogram_jail1 <- ggplot(na.omit(jail))+
geom_bar(aes(x=Age,
fill = Race))+
facet_wrap(~Race)+
labs(x= "Age",
y = "Number of people",
title = "Jail Data")
# histogram of stop data by race and hour:
histogram_stoptime1 <- ggplot(stops, aes(x = Hour, fill = Race)) +
geom_bar(aes(y = ..count..)) +
labs(y = "Count") +
facet_grid(~Race)+
labs(title = "Number of people each race in every hour") +
guides( fill = FALSE )
panderOptions("digits", 2)
pander(ss) # table for stop data percentages by race relative to population
grid.arrange(bargraph1, bargraph2, ncol = 2)
panderOptions("digits", 3)
pander(ss) # table for stop data percentages by race relative to population
#grid.arrange(bargraph1, bargraph2, ncol = 2)
map_arrested1
stopdensitymap
map_reasons1
histogram_jail1
# arrest data histogram by race
histogram_arrest1 <- ggplot(na.omit(arrest))+
geom_bar(aes(x=Age,
fill = Race))+
facet_grid(~Race)+
labs(x= "Age",
y = "Number of people",
title = "Arrest Data")
# jail data histogram by race
histogram_jail1 <- ggplot(na.omit(jail))+
geom_bar(aes(x=Age,
fill = Race))+
facet_grid(~Race)+
labs(x= "Age",
y = "Number of people",
title = "Jail Data")
# histogram of stop data by race and hour:
histogram_stoptime1 <- ggplot(stops, aes(x = Hour, fill = Race)) +
geom_bar(aes(y = ..count..)) +
labs(y = "Count") +
facet_grid(~Race)+
labs(title = "Number of people each race in every hour") +
guides( fill = FALSE )
histogram_jail1
histogram_arrest1
histogram_arrest1 <- ggplot(na.omit(arrest))+
geom_bar(aes(x=Age,
fill = Race))+
facet_grid(~Race)+
labs(x= "Age",
y = "Number of people",
title = "Arrest Data") +
guides( fill = FALSE)
# jail data histogram by race
histogram_jail1 <- ggplot(na.omit(jail))+
geom_bar(aes(x=Age,
fill = Race))+
facet_grid(~Race)+
labs(x= "Age",
y = "Number of people",
title = "Jail Data") +
guides(fill = FALSE)
histogram_jail1
histogram_arrest1
histogram_stoptime1
